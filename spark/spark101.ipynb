{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"exercises\">Exercises - Spark API</h2>\n",
    "<p>Create a directory named <code>spark</code> within your <code>ds-methodologies</code> repository. This is where you will do the exercises for this module.</p>\n",
    "<p>Create a jupyter notebook or python script named <code>spark101</code> for this exercise.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydataset import data\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "[(Up to top)](#Exercises---Spark-API)\n",
    "[(Down to 2)](#2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a\n",
    "The name of the column should be <code>language</code>\n",
    "\n",
    "[(Back to 1)](#1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "langlist = [['Python', \"https://www.python.org/\", 9], \n",
    "            ['SQL', '', 8], \n",
    "            ['R', 'https://www.r-project.org/about.html', 2], \n",
    "            ['C++', 'http://www.cplusplus.com/', 2], \n",
    "            ['Java', \"https://www.java.com/en/\", 1], \n",
    "            ['JavaScript', \"https://www.javascript.com/\", 2], \n",
    "            ['Bash', 'https://www.gnu.org/software/bash/', 1], \n",
    "            ['MATLAB', 'https://www.mathworks.com/products/matlab.html', 4], \n",
    "            ['C#', 'https://docs.microsoft.com/en-us/dotnet/csharp/', 2], \n",
    "            ['.NET', 'https://dotnet.microsoft.com/', 5], \n",
    "            ['Visual Basic', 'https://docs.microsoft.com/en-us/dotnet/visual-basic/', 7], \n",
    "            ['PHP', 'https://www.php.net/', 3], \n",
    "            ['STATA', 'https://www.stata.com/', 4], \n",
    "            ['Scala', 'https://www.scala-lang.org/', 4], \n",
    "            ['Go', 'https://golang.org/', 6], \n",
    "            ['Ruby', 'https://www.ruby-lang.org/en/', 4], \n",
    "            ['Julia', 'https://julialang.org/', 5]\n",
    "           ]\n",
    "langpd = pd.DataFrame(langlist, columns=['language','url','kevscore'])\n",
    "langdf = spark.createDataFrame(langpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b\n",
    "View the schema of the dataframe\n",
    "\n",
    "[(Back to 1)](#1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- kevscore: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "langdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c\n",
    "Output the shape of the dataframe\n",
    "\n",
    "[(Back to 1)](#1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'({langdf.count()}, {len(langdf.columns)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.d\n",
    "\n",
    "Show the first 5 records in the dataframe\n",
    "\n",
    "[(Back to 1)](#1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------------------------------------------+--------+\n",
      "|language    |url                                                  |kevscore|\n",
      "+------------+-----------------------------------------------------+--------+\n",
      "|Python      |https://www.python.org/                              |9       |\n",
      "|SQL         |                                                     |8       |\n",
      "|Visual Basic|https://docs.microsoft.com/en-us/dotnet/visual-basic/|7       |\n",
      "|Go          |https://golang.org/                                  |6       |\n",
      "|.NET        |https://dotnet.microsoft.com/                        |5       |\n",
      "|Julia       |https://julialang.org/                               |5       |\n",
      "|MATLAB      |https://www.mathworks.com/products/matlab.html       |4       |\n",
      "|Ruby        |https://www.ruby-lang.org/en/                        |4       |\n",
      "|STATA       |https://www.stata.com/                               |4       |\n",
      "|Scala       |https://www.scala-lang.org/                          |4       |\n",
      "+------------+-----------------------------------------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "langdf.sort(F.desc('kevscore'), 'language').show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "Load the <code>mpg</code> dataset as a spark dataframe.</p>\n",
    "\n",
    "[(Up to top)](#Exercises---Spark-API)\n",
    "[(Up to 1)](#1)\n",
    "[(Down to 3)](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|   trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|auto(l5)|  f| 18| 29|  p|compact|\n",
      "+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a\n",
    "Create 1 column of output that contains a message like the one below:</p>\n",
    "<pre><code>The 1999 audi a4 has a 4 cylinder engine.</code></pre>\n",
    "For each vehicle.</p>\n",
    "\n",
    "[(Back to 2)](#2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+\n",
      "|descriptive_sentence                                          |\n",
      "+--------------------------------------------------------------+\n",
      "|The 2 2008 chevrolet k1500 tahoe 4wds have 8 cylinder engines.|\n",
      "|The 2 2008 volkswagen new beetles have 5 cylinder engines.    |\n",
      "|The 2 1999 audi a4 quattros have 6 cylinder engines.          |\n",
      "|The 2 2008 toyota corollas have 4 cylinder engines.           |\n",
      "|The 2008 audi a6 quattro has a 8 cylinder engine.             |\n",
      "|The 2008 volkswagen passat has a 6 cylinder engine.           |\n",
      "|The 2008 nissan maxima has a 6 cylinder engine.               |\n",
      "|The 3 1999 pontiac grand prixs have 6 cylinder engines.       |\n",
      "|The 2 1999 chevrolet corvettes have 8 cylinder engines.       |\n",
      "|The 2008 ford explorer 4wd has a 6 cylinder engine.           |\n",
      "|The 2008 audi a6 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 toyota camry solara has a 6 cylinder engine.         |\n",
      "|The 2 2008 nissan altimas have 6 cylinder engines.            |\n",
      "|The 2 1999 toyota camrys have 6 cylinder engines.             |\n",
      "|The 4 2008 jeep grand cherokee 4wds have 8 cylinder engines.  |\n",
      "+--------------------------------------------------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(mpg\n",
    " .groupBy('manufacturer', 'model', 'year', 'cyl')\n",
    " .agg(F.count('*').alias('cars'))\n",
    " .select(\n",
    "     F.concat(\n",
    "        F.lit('The '),\n",
    "        (F.when(F.col('cars') == 1, F.lit(''))\n",
    "            .otherwise(F.col('cars'))), \n",
    "        (F.when(F.col('cars') == 1, F.lit(''))\n",
    "            .otherwise(F.lit(' '))), \n",
    "        'year', F.lit(' '), 'manufacturer', \n",
    "        F.lit(' '), 'model', \n",
    "        (F.when(F.col('cars') == 1, F.lit(' has a '))\n",
    "            .otherwise(F.lit('s have '))), \n",
    "        'cyl', F.lit(' cylinder engine'),\n",
    "        (F.when(F.col('cars') == 1, F.lit('.'))\n",
    "            .otherwise(F.lit('s.'))), \n",
    "\n",
    "    ).alias('descriptive_sentence')).show(15, truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b\n",
    "Transform the <code>trans</code> column so that it only contains either <code>manual</code> or <code>auto</code>.\n",
    "\n",
    "[(Back to 2)](#2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----+----+---+---+---+---+---+-------+---------+\n",
      "|manufacturer|     model|displ|year|cyl|drv|cty|hwy| fl|  class|transtype|\n",
      "+------------+----------+-----+----+---+---+---+---+---+-------+---------+\n",
      "|        audi|        a4|  1.8|1999|  4|  f| 18| 29|  p|compact|     auto|\n",
      "|        audi|        a4|  1.8|1999|  4|  f| 21| 29|  p|compact|   manual|\n",
      "|        audi|        a4|  2.0|2008|  4|  f| 20| 31|  p|compact|   manual|\n",
      "|        audi|        a4|  2.0|2008|  4|  f| 21| 30|  p|compact|     auto|\n",
      "|        audi|        a4|  2.8|1999|  6|  f| 16| 26|  p|compact|     auto|\n",
      "|        audi|        a4|  2.8|1999|  6|  f| 18| 26|  p|compact|   manual|\n",
      "|        audi|        a4|  3.1|2008|  6|  f| 18| 27|  p|compact|     auto|\n",
      "|        audi|a4 quattro|  1.8|1999|  4|  4| 18| 26|  p|compact|   manual|\n",
      "|        audi|a4 quattro|  1.8|1999|  4|  4| 16| 25|  p|compact|     auto|\n",
      "|        audi|a4 quattro|  2.0|2008|  4|  4| 20| 28|  p|compact|   manual|\n",
      "+------------+----------+-----+----+---+---+---+---+---+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(mpg.select(\n",
    "    '*', (\n",
    "        F.when(mpg.trans.like('auto%'), 'auto')\n",
    "        .when(mpg.trans.like('manual%'), 'manual')\n",
    "        .otherwise('unknown')\n",
    "        .alias('transtype')))\n",
    "    .drop('trans')).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "Load the <code>tips</code> dataset as a spark dataframe.\n",
    "\n",
    "[(Up to top)](#Exercises---Spark-API)\n",
    "[(Up to 2)](#2)\n",
    "[(Down to 4)](#4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "\n",
    "tips = spark.createDataFrame(data(\"tips\"))\n",
    "tips.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a\n",
    "What percentage of observations are smokers?\n",
    "\n",
    "[(Back to 3)](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|        avg(smokes)|\n",
      "+-------------------+\n",
      "|0.38114754098360654|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.select(F.when(tips.smoker == 'Yes', 1).otherwise(0).alias('smokes')).agg(F.avg('smokes')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b\n",
    "Create a column that contains the tip percentage\n",
    "\n",
    "[(Back to 3)](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+--------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|tip_pctg|\n",
      "+----------+----+------+------+---+------+----+--------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2| 0.05945|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3| 0.16054|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3| 0.16659|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.13978|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4| 0.14681|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4| 0.18624|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2| 0.22805|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4| 0.11607|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2| 0.13032|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2| 0.21854|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|  0.1665|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|  0.1418|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2| 0.10182|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4| 0.16278|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2| 0.20364|\n",
      "+----------+----+------+------+---+------+----+--------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tipswpctg = tips.select('*', F.round((tips.tip / tips.total_bill),5).alias('tip_pctg'))\n",
    "tipswpctg.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c\n",
    "Calculate the average tip percentage for each combination of sex and smoker.\n",
    "\n",
    "[(Back to 3)](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------+--------------+\n",
      "|   sex|smoker|avg_tip_pctg|gross_tip_pctg|\n",
      "+------+------+------------+--------------+\n",
      "|  Male|    No|     0.16067|       0.15731|\n",
      "|  Male|   Yes|     0.15277|       0.13692|\n",
      "|Female|    No|     0.15692|       0.15319|\n",
      "|Female|   Yes|     0.18215|       0.16306|\n",
      "+------+------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(tipswpctg\n",
    " .groupBy('sex','smoker')\n",
    " .agg(\n",
    "     F.round(F.avg('tip_pctg'),5).alias('avg_tip_pctg'), \n",
    "     F.round((F.sum('tip')/F.sum('total_bill')), 5).alias('gross_tip_pctg')\n",
    " )).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "Use the seattle weather dataset referenced in the lesson to answer the questions below.</p>\n",
    "\n",
    "[(Up to top)](#Exercises---Spark-API)\n",
    "[(Up to 3)](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- precipitation: double (nullable = true)\n",
      " |-- temp_max: double (nullable = true)\n",
      " |-- temp_min: double (nullable = true)\n",
      " |-- wind: double (nullable = true)\n",
      " |-- weather: string (nullable = true)\n",
      "\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather.printSchema()\n",
    "weather.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a\n",
    "Convert the temperatures to farenheight.\n",
    "\n",
    "[(Back to 4)](#4)\n",
    "[(Go to function test)](#4.a.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|id_c_to_f|\n",
      "+---+---------+\n",
      "|  1|     33.8|\n",
      "|  2|     35.6|\n",
      "|  3|     37.4|\n",
      "|  4|     39.2|\n",
      "|  5|     41.0|\n",
      "+---+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.types as T\n",
    "\n",
    "def c_to_f(temp_c):\n",
    "    return (9 * temp_c * .2) + 32\n",
    "\n",
    "spark.udf.register(\"degreesCtoF\", c_to_f, T.DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+----------+--------+----------+----+-------+----------+\n",
      "|      date|precipitation|temp_max|temp_max_f|temp_min|temp_min_f|wind|weather|year_month|\n",
      "+----------+-------------+--------+----------+--------+----------+----+-------+----------+\n",
      "|2012-01-01|          0.0|    12.8|      55.0|     5.0|      41.0| 4.7|drizzle|   2012-01|\n",
      "|2012-01-02|         10.9|    10.6|      51.1|     2.8|      37.0| 4.5|   rain|   2012-01|\n",
      "|2012-01-03|          0.8|    11.7|      53.1|     7.2|      45.0| 2.3|   rain|   2012-01|\n",
      "|2012-01-04|         20.3|    12.2|      54.0|     5.6|      42.1| 4.7|   rain|   2012-01|\n",
      "|2012-01-05|          1.3|     8.9|      48.0|     2.8|      37.0| 6.1|   rain|   2012-01|\n",
      "+----------+-------------+--------+----------+--------+----------+----+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weatherfm = weatherf.select(\n",
    "    'date', 'precipitation', 'temp_max', 'temp_max_f', 'temp_min', 'temp_min_f', 'wind', 'weather',\n",
    "    F.expr('LEFT(date, 7) year_month')\n",
    ")\n",
    "weatherfm.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+----------+----------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|temp_max_f|temp_min_f|\n",
      "+----------+-------------+--------+--------+----+-------+----------+----------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|      55.0|      41.0|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|      51.1|      37.0|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|      53.1|      45.0|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|      54.0|      42.1|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|      48.0|      37.0|\n",
      "+----------+-------------+--------+--------+----+-------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weatherf = weather.select(\n",
    "    '*', \n",
    "   F.expr('round(degreesCtoF(temp_max),1) temp_max_f'), \n",
    "   F.expr('round(degreesCtoF(temp_min),1) temp_min_f')\n",
    ")\n",
    "weatherf.show(5)\n",
    "# type(temp_max_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----------+--------+\n",
      "|year_month|days|tot_precip|avg_wind|\n",
      "+----------+----+----------+--------+\n",
      "|   2012-01|  31|     173.3|     3.9|\n",
      "|   2012-02|  29|      92.3|     3.9|\n",
      "|   2012-03|  31|     183.0|    4.25|\n",
      "|   2012-04|  30|      68.1|    3.37|\n",
      "|   2012-05|  31|      52.2|    3.35|\n",
      "+----------+----+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weatherfmgym = (\n",
    "    weatherfm\n",
    "    .groupby('year_month')\n",
    "    .agg(\n",
    "        F.count('date').alias('days'), \n",
    "        F.round(F.sum('precipitation'), 2).alias('tot_precip'), \n",
    "        F.round(F.avg('wind'), 2).alias('avg_wind')\n",
    "    )\n",
    "    .sort('year_month')\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---+----+----+---+\n",
      "|year_month|drizzle|fog|rain|snow|sun|\n",
      "+----------+-------+---+----+----+---+\n",
      "|   2012-01|      2|  0|  18|   7|  4|\n",
      "|   2012-02|      1|  0|  17|   3|  8|\n",
      "|   2012-03|      1|  0|  19|   5|  6|\n",
      "|   2012-04|      2|  0|  19|   1|  8|\n",
      "|   2012-05|      1|  0|  16|   0| 14|\n",
      "+----------+-------+---+----+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weatherfmpymw = (\n",
    "    weatherfm\n",
    "    .groupby('year_month')\n",
    "    .pivot('weather')\n",
    "    .agg(\n",
    "        F.count('date').alias('days')\n",
    "    )\n",
    "    .sort('year_month')\n",
    "    .na.fill(0)\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.b\n",
    "Which month has the most rain, on average?\n",
    "\n",
    "[(Back to 4)](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.c\n",
    "Which year was the windiest?\n",
    "\n",
    "[(Back to 4)](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.d\n",
    "What is the most frequent type of weather in January?\n",
    "\n",
    "[(Back to 4)](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.e\n",
    "What is the average high and low tempurature on sunny days in July in 2013 and 2014?\n",
    "\n",
    "[(Back to 4)](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.f\n",
    "What percentage of days were rainy in q3 of 2015?\n",
    "\n",
    "[(Back to 4)](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.g\n",
    "For each year, find what percentage of days it rained (had non-zero precipitation).\n",
    "\n",
    "[(Back to 4)](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a.test\n",
    "[(Back to 4.a)](#4.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|         id_c_to_f|\n",
      "+---+------------------+\n",
      "|  1|              33.8|\n",
      "|  2|              35.6|\n",
      "|  3|              37.4|\n",
      "|  4|              39.2|\n",
      "|  5|              41.0|\n",
      "|  6|              42.8|\n",
      "|  7|              44.6|\n",
      "|  8|              46.4|\n",
      "|  9|              48.2|\n",
      "| 10|              50.0|\n",
      "| 11|              51.8|\n",
      "| 12|              53.6|\n",
      "| 13|55.400000000000006|\n",
      "| 14|              57.2|\n",
      "| 15|              59.0|\n",
      "| 16|              60.8|\n",
      "| 17|              62.6|\n",
      "| 18|              64.4|\n",
      "| 19|              66.2|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(1, 20).registerTempTable(\"test\")\n",
    "spark.sql('''select id, degreesCtoF(id) as id_c_to_f from test''').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
